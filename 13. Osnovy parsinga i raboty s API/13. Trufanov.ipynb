{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL = 'https://habr.com/ru/all/'\n",
    "res = requests.get(URL)\n",
    "\n",
    "KEYWORDS = ['python', 'работа', 'игры']\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "data_dict = {\n",
    "    'date': [],\n",
    "    'title': [],\n",
    "    'link': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_data(url, page):\n",
    "    if page != 1:\n",
    "        url = url + '/page' + str(page)\n",
    "    res = requests.get(url)\n",
    "    time.sleep(0.3)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    posts = soup.find_all('article', class_='post post_preview')\n",
    "    for post in posts:\n",
    "        hubs = post.find_all('a', class_='post__title_link')\n",
    "        post_time = post.find('span', class_='post__time').text\n",
    "        for hub in hubs:\n",
    "            hub_lower = hub.text.lower()\n",
    "            for keyword in KEYWORDS:\n",
    "                if keyword in hub_lower:\n",
    "                    title_element = post.find('a', class_='post__title_link')\n",
    "                    return post_time, title_element.text, title_element.attrs.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нашлось на станице новостей №1\n",
      "Нашлось на станице новостей №2\n",
      "Нашлось на станице новостей №4\n",
      "Нашлось на станице новостей №5\n"
     ]
    }
   ],
   "source": [
    "for page in range(1,10):\n",
    "    if get_url_data(URL, page):\n",
    "        print(f'Нашлось на станице новостей №{page}')\n",
    "        date, title, link = get_url_data(URL, page)\n",
    "        data_dict['date'].append(date)\n",
    "        data_dict['title'].append(title)\n",
    "        data_dict['link'].append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>сегодня в 18:44</td>\n",
       "      <td>Создание арт-объектов, игр и много чего ещё с ...</td>\n",
       "      <td>https://habr.com/ru/company/skillfactory/blog/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>сегодня в 14:58</td>\n",
       "      <td>Как мы визуальный конструктор обучения цифровы...</td>\n",
       "      <td>https://habr.com/ru/company/neuronet/blog/548934/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>сегодня в 10:01</td>\n",
       "      <td>Как этот год работала наша внутренняя служба г...</td>\n",
       "      <td>https://habr.com/ru/company/croc/blog/548768/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>вчера в 18:00</td>\n",
       "      <td>Работаем с lightsquid или как сделать индивиду...</td>\n",
       "      <td>https://habr.com/ru/post/548782/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сегодня в 18:44</td>\n",
       "      <td>Создание арт-объектов, игр и много чего ещё с ...</td>\n",
       "      <td>https://habr.com/ru/company/skillfactory/blog/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>сегодня в 14:58</td>\n",
       "      <td>Как мы визуальный конструктор обучения цифровы...</td>\n",
       "      <td>https://habr.com/ru/company/neuronet/blog/548934/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>сегодня в 10:01</td>\n",
       "      <td>Как этот год работала наша внутренняя служба г...</td>\n",
       "      <td>https://habr.com/ru/company/croc/blog/548768/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>вчера в 18:00</td>\n",
       "      <td>Работаем с lightsquid или как сделать индивиду...</td>\n",
       "      <td>https://habr.com/ru/post/548782/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                                              title  \\\n",
       "0  сегодня в 18:44  Создание арт-объектов, игр и много чего ещё с ...   \n",
       "1  сегодня в 14:58  Как мы визуальный конструктор обучения цифровы...   \n",
       "2  сегодня в 10:01  Как этот год работала наша внутренняя служба г...   \n",
       "3    вчера в 18:00  Работаем с lightsquid или как сделать индивиду...   \n",
       "4  сегодня в 18:44  Создание арт-объектов, игр и много чего ещё с ...   \n",
       "5  сегодня в 14:58  Как мы визуальный конструктор обучения цифровы...   \n",
       "6  сегодня в 10:01  Как этот год работала наша внутренняя служба г...   \n",
       "7    вчера в 18:00  Работаем с lightsquid или как сделать индивиду...   \n",
       "\n",
       "                                                link  \n",
       "0  https://habr.com/ru/company/skillfactory/blog/...  \n",
       "1  https://habr.com/ru/company/neuronet/blog/548934/  \n",
       "2      https://habr.com/ru/company/croc/blog/548768/  \n",
       "3                   https://habr.com/ru/post/548782/  \n",
       "4  https://habr.com/ru/company/skillfactory/blog/...  \n",
       "5  https://habr.com/ru/company/neuronet/blog/548934/  \n",
       "6      https://habr.com/ru/company/croc/blog/548768/  \n",
       "7                   https://habr.com/ru/post/548782/  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_news = pd.DataFrame(data_dict)\n",
    "filtered_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса [Avast Hack Ckeck](https://www.avast.com/hackcheck/).\n",
    "Список email-ов задаем переменной в начале кода:  \n",
    "`EMAIL = [xxx@x.ru, yyy@y.com]`\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: `<почта> - <дата утечки> - <источник утечки> - <описание утечки>`  \n",
    "\n",
    "**Подсказка**: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [400]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "params = {\n",
    "        'emailAddresses': [\"yy@ya.ru\",\"xx@ya.ru\", \"12@wwwww.ru\"]\n",
    "    }\n",
    "\n",
    "URL = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "\n",
    "headers = {\n",
    "    'Host': 'identityprotection.avast.com',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Content-Length': '34',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"87\", \" Not;A Brand\";v=\"99\", \"Chromium\";v=\"87\"',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Vaar-Version': '0',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',\n",
    "    'Vaar-Header-App-Product': 'hackcheck-web-avast',\n",
    "    'Content-Type': 'application/json;charset=UTF-8',\n",
    "    'Origin': 'https://www.avast.com',\n",
    "    'Sec-Fetch-Site': 'same-site',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Referer': 'https://www.avast.com/',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "res = requests.post(URL, headers=headers, json=params)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b49df64d14b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbreaches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "breaches = json.loads(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fc-zenit.ru': {'yy@ya.ru': [{'breachId': 3701,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " 'cfire.mail.ru': {'yy@ya.ru': [{'breachId': 3164,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " 'storelp.ru': {'xx@ya.ru': [{'breachId': 14357,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " 'vk.com': {'yy@ya.ru': [{'breachId': 12,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}],\n",
       "  'xx@ya.ru': [{'breachId': 12,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breaches['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_leak_dict = {\n",
    "    'email': [],\n",
    "    'leak_date': [],\n",
    "    'leak_source': [],\n",
    "    'leak_title': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yy@ya.ru {'breaches': [12, 3164, 3701]}\n",
      "xx@ya.ru {'breaches': [14357, 12]}\n",
      "12@wwwww.ru {'breaches': []}\n"
     ]
    }
   ],
   "source": [
    "for key, value in breaches['summary'].items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in breaches['summary'].items():\n",
    "    email = key\n",
    "    if not value['breaches']:\n",
    "        email_leak_dict['email'].append(email)\n",
    "        email_leak_dict['leak_date'].append('no breach')\n",
    "        email_leak_dict['leak_source'].append('no breach')\n",
    "        email_leak_dict['leak_title'].append('no breach')\n",
    "    for breach in value['breaches']:\n",
    "        leak_date = breaches['breaches'][str(breach)]['publishDate']\n",
    "        leak_source = breaches['breaches'][str(breach)]['site']\n",
    "        leak_title = breaches['breaches'][str(breach)]['description']\n",
    "        email_leak_dict['email'].append(email)\n",
    "        email_leak_dict['leak_date'].append(leak_date)\n",
    "        email_leak_dict['leak_source'].append(leak_source)\n",
    "        email_leak_dict['leak_title'].append(leak_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email': ['yy@ya.ru',\n",
       "  'yy@ya.ru',\n",
       "  'yy@ya.ru',\n",
       "  'xx@ya.ru',\n",
       "  'xx@ya.ru',\n",
       "  '12@wwwww.ru'],\n",
       " 'leak_date': ['2016-10-29T00:00:00Z',\n",
       "  '2017-02-14T00:00:00Z',\n",
       "  '2017-03-31T00:00:00Z',\n",
       "  '2018-06-19T00:00:00Z',\n",
       "  '2016-10-29T00:00:00Z',\n",
       "  'no breach'],\n",
       " 'leak_source': ['vk.com',\n",
       "  'cfire.mail.ru',\n",
       "  'fc-zenit.ru',\n",
       "  'storelp.ru',\n",
       "  'vk.com',\n",
       "  'no breach'],\n",
       " 'leak_title': [\"Popular Russian social networking platform VKontakte was breached in late 2012. Over 100 million clear-text passwords were compromised in the breach. Breached credential sets included victims' e-mail addresses, passwords, dates of birth, phone numbers and location details. The credential set was advertised on a dark web marketplace as of June 2016 for a price of one bitcoin. \",\n",
       "  \"In July and August of 2016, two criminals carried out attacks on three separate forums hosted by Mail.ru, including CFire. The hackers used known SQL injection vulnerabilities found in older vBulletin forum software to obtain access to the databases. Shortly after the breach itself, the contents of CFire's database were leaked publicly. The database contains usernames, email addresses, and MD5 hashed passwords for just under 13 million users.\",\n",
       "  \"In July 2010, FC Zenit's user database was allegedly breached. The stolen data contains over 90,000 records including email addresses and passwords. The compromised data is being shared privately on the darknet.\",\n",
       "  \"At an unconfirmed date, StoreLP.ru's database was allegedly breached. The stolen data contains passwords and email addresses. This breach is being privately shared on the internet.\",\n",
       "  \"Popular Russian social networking platform VKontakte was breached in late 2012. Over 100 million clear-text passwords were compromised in the breach. Breached credential sets included victims' e-mail addresses, passwords, dates of birth, phone numbers and location details. The credential set was advertised on a dark web marketplace as of June 2016 for a price of one bitcoin. \",\n",
       "  'no breach']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_leak_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>leak_date</th>\n",
       "      <th>leak_source</th>\n",
       "      <th>leak_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yy@ya.ru</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yy@ya.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>cfire.mail.ru</td>\n",
       "      <td>In July and August of 2016, two criminals carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yy@ya.ru</td>\n",
       "      <td>2017-03-31T00:00:00Z</td>\n",
       "      <td>fc-zenit.ru</td>\n",
       "      <td>In July 2010, FC Zenit's user database was all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xx@ya.ru</td>\n",
       "      <td>2018-06-19T00:00:00Z</td>\n",
       "      <td>storelp.ru</td>\n",
       "      <td>At an unconfirmed date, StoreLP.ru's database ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xx@ya.ru</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12@wwwww.ru</td>\n",
       "      <td>no breach</td>\n",
       "      <td>no breach</td>\n",
       "      <td>no breach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         email             leak_date    leak_source  \\\n",
       "0     yy@ya.ru  2016-10-29T00:00:00Z         vk.com   \n",
       "1     yy@ya.ru  2017-02-14T00:00:00Z  cfire.mail.ru   \n",
       "2     yy@ya.ru  2017-03-31T00:00:00Z    fc-zenit.ru   \n",
       "3     xx@ya.ru  2018-06-19T00:00:00Z     storelp.ru   \n",
       "4     xx@ya.ru  2016-10-29T00:00:00Z         vk.com   \n",
       "5  12@wwwww.ru             no breach      no breach   \n",
       "\n",
       "                                          leak_title  \n",
       "0  Popular Russian social networking platform VKo...  \n",
       "1  In July and August of 2016, two criminals carr...  \n",
       "2  In July 2010, FC Zenit's user database was all...  \n",
       "3  At an unconfirmed date, StoreLP.ru's database ...  \n",
       "4  Popular Russian social networking platform VKo...  \n",
       "5                                          no breach  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_leak = pd.DataFrame(email_leak_dict)\n",
    "email_leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL = 'https://habr.com/ru/all/'\n",
    "res = requests.get(URL)\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "posts = soup.find_all('article', class_='post post_preview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_data(url, page):\n",
    "    if page != 1:\n",
    "        url = url + '/page' + str(page)\n",
    "    res = requests.get(url)\n",
    "    time.sleep(0.3)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    posts = soup.find_all('article', class_='post post_preview')\n",
    "    for post in posts:\n",
    "        hubs = post.find_all('a', class_='post__title_link')\n",
    "        post_time = post.find('span', class_='post__time').text\n",
    "        for hub in hubs:\n",
    "            hub_lower = hub.text.lower()\n",
    "            for keyword in KEYWORDS:\n",
    "                if keyword in hub_lower:\n",
    "                    title_element = post.find('a', class_='post__title_link')\n",
    "                    return post_time, title_element.text, title_element.attrs.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'date': [],\n",
    "    'title': [],\n",
    "    'link': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нашлось на станице новостей №1\n"
     ]
    }
   ],
   "source": [
    "for page in range(1,10):\n",
    "    if get_url_data(URL, page):\n",
    "        print(f'Нашлось на станице новостей №{page}')\n",
    "        date, title, link = get_url_data(URL, page)\n",
    "        data_dict['date'].append(date)\n",
    "        data_dict['title'].append(title)\n",
    "        data_dict['link'].append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>сегодня в 18:44</td>\n",
       "      <td>Создание арт-объектов, игр и много чего ещё с ...</td>\n",
       "      <td>https://habr.com/ru/company/skillfactory/blog/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                                              title  \\\n",
       "0  сегодня в 18:44  Создание арт-объектов, игр и много чего ещё с ...   \n",
       "\n",
       "                                                link  \n",
       "0  https://habr.com/ru/company/skillfactory/blog/...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_news = pd.DataFrame(data_dict)\n",
    "filtered_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
